{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9LLxe7K75tG"
   },
   "source": [
    "## 1.Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5DNpgp291Rh",
    "outputId": "89f46c5a-fea3-4fba-f829-f6544102e643"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define path\n",
    "data_path = '../datasets/student_grade.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s7YDtxwjreA"
   },
   "source": [
    "## 2.Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "z8093Ih11_HZ",
    "outputId": "80ee09d7-13fe-46e9-c686-2caed13354c1"
   },
   "outputs": [],
   "source": [
    "# === 2.1 Load Data ===\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "# === 2.2 Transform Data (Wide to Long) ===\n",
    "id_vars = ['student_id']\n",
    "df_long = pd.melt(df, id_vars=id_vars, var_name='course', value_name='grade')\n",
    "\n",
    "# === 2.3 Clean Data ===\n",
    "# Convert grade to numeric and remove invalid/empty grades\n",
    "df_long['grade'] = pd.to_numeric(df_long['grade'], errors='coerce')\n",
    "df_long_cleaned = df_long[(df_long['grade'] > 0.0) & (df_long['grade'].notna())].copy()\n",
    "\n",
    "# === 2.4 Filter for 'INT' Courses Only ===\n",
    "# This ensures the model only learns from INT courses\n",
    "df_long_filtered = df_long_cleaned[df_long_cleaned['course'].astype(str).str.startswith('INT')].copy()\n",
    "\n",
    "print(f\"--- Data Preparation Complete ---\")\n",
    "print(f\"Total records after cleaning: {len(df_long_cleaned)}\")\n",
    "print(f\"Filtered to INT courses only: {len(df_long_filtered)}\")\n",
    "display(df_long_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2PvDHolfQQl"
   },
   "source": [
    "## 3.Split Data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW9IQUP-fhEA"
   },
   "outputs": [],
   "source": [
    "# === 3.1 Load Data into Surprise Dataset ===\n",
    "# Define rating scale (assuming grades are 1.0 to 4.0)\n",
    "reader = Reader(rating_scale=(1, 4))\n",
    "data = Dataset.load_from_df(df_long_filtered[['student_id', 'course', 'grade']], reader)\n",
    "\n",
    "# === 3.2 Split Data ===\n",
    "trainset, testset = train_test_split(data, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u15hmTyy9i-J"
   },
   "source": [
    "## 4.Model Training (KNNBasic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4HTGZpnG9m-1",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b89d1d05-d433-4bde-a9b6-75757820c014"
   },
   "outputs": [],
   "source": [
    "# === 3.3 Train the Model ===\n",
    "print(\"--- Training KNN Model (User - User) ---\")\n",
    "sim_user = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": True\n",
    "}\n",
    "\n",
    "algo_user = KNNBasic(sim_options=sim_user)\n",
    "algo_user.fit(trainset)\n",
    "print(\"Training KNN Model (User - User) complete.\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"--- Training KNN Model (Item - Item) ---\")\n",
    "sim_item = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False\n",
    "}\n",
    "\n",
    "algo_item = KNNBasic(sim_options=sim_item)\n",
    "algo_item.fit(trainset)\n",
    "print(\"Training KNN Model (Item - Item) complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMAJ3JIaQCwk"
   },
   "outputs": [],
   "source": [
    "def recommend_for_user(algo, user_id, n=5):\n",
    "    items = trainset.all_items()\n",
    "    items_raw = [trainset.to_raw_iid(i) for i in items]\n",
    "\n",
    "    predictions = [\n",
    "        (iid, algo.predict(user_id, iid).est)\n",
    "        for iid in items_raw\n",
    "    ]\n",
    "\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return predictions[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyzIrYXWQBje"
   },
   "outputs": [],
   "source": [
    "def similar_items(algo, item_raw_id, k=5):\n",
    "    inner = algo.trainset.to_inner_iid(item_raw_id)\n",
    "    neighbors = algo.get_neighbors(inner, k=k)\n",
    "    raw_ids = [algo.trainset.to_raw_iid(i) for i in neighbors]\n",
    "    return raw_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcPoer3d4M9x",
    "outputId": "04a64d30-6c3e-4032-880d-1d4fb3a64be1"
   },
   "outputs": [],
   "source": [
    "recommend_for_user(algo_user, \"A246\", n=10) # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ä‡∏≤‡πÉ‡∏´‡πâ student_id = A246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcVzmwqJgwE8",
    "outputId": "67cc822a-c90f-4541-fe70-620c050bb866"
   },
   "outputs": [],
   "source": [
    "similar_items(algo_item, \"INT102 WEB TECHNOLOGY\") # ‡∏ß‡∏¥‡∏ä‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPJ-s7_-gIR6"
   },
   "source": [
    "## 5.Test and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HlfvVLV_4XR",
    "outputId": "1bb941ac-8eda-40c0-ceeb-94a169ca8d15"
   },
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# Predict on testset\n",
    "pred_user = algo_user.test(testset)\n",
    "pred_item = algo_item.test(testset)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== USER‚ÄìUSER KNN PERFORMANCE ===\")\n",
    "accuracy.rmse(pred_user)\n",
    "accuracy.mae(pred_user)\n",
    "\n",
    "print(\"\\n=== ITEM‚ÄìITEM KNN PERFORMANCE ===\")\n",
    "accuracy.rmse(pred_item)\n",
    "accuracy.mae(pred_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4u7eqMGzBJQ0",
    "outputId": "f176e81d-af1c-4861-8bc9-e2b69a3a5b78"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "cross_validate(algo_user, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzN2ACa0UBQZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_classification(predictions, threshold=2):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for p in predictions:\n",
    "        true_r = p.r_ui\n",
    "        pred_r = p.est\n",
    "\n",
    "        # Convert ratings ‚Üí class\n",
    "        y_true.append(1 if true_r >= threshold else 0)\n",
    "        y_pred.append(1 if pred_r >= threshold else 0)\n",
    "\n",
    "    metrics = {\n",
    "        \"R-score\": np.corrcoef(y_true, y_pred)[0, 1],  # Correlation\n",
    "        \"Precision-Macro\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"Recall-Macro\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"F1-Macro\": f1_score(y_true, y_pred, average='macro'),\n",
    "        \"Precision-Weighted\": precision_score(y_true, y_pred, average='weighted'),\n",
    "        \"Recall-Weighted\": recall_score(y_true, y_pred, average='weighted'),\n",
    "        \"F1-Weighted\": f1_score(y_true, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-46c9WArUGjS",
    "outputId": "b2558837-9d13-4426-d162-384e452e0601"
   },
   "outputs": [],
   "source": [
    "metrics_user = evaluate_classification(pred_user, threshold=3)\n",
    "metrics_user\n",
    "\n",
    "metrics_item = evaluate_classification(pred_item, threshold=3)\n",
    "metrics_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ECuxutzybI-",
    "outputId": "67829bb9-f8d8-4296-fc0c-aaf97880f3a4"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# === 4.1 Predict for Unknown Items ===\n",
    "print(\"--- Generating Predictions for all missing pairs ---\")\n",
    "anti_testset = trainset.build_anti_testset()\n",
    "all_predictions = algo_user.test(anti_testset)\n",
    "\n",
    "# === 4.2 Helper Function for Top-N ===\n",
    "def get_top_n(predictions, n=5):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\"\"\"\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "# === 4.3 Generate Top 5 Recommendations ===\n",
    "top_n_recommendations = get_top_n(all_predictions, n=5)\n",
    "print(f\"Generated recommendations for {len(top_n_recommendations)} students.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLxgr8tLVV0k",
    "outputId": "030b0a38-408b-4abb-f8dc-479de2c8d863"
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# === Calculate Precision@K and Recall@K ===================\n",
    "# =========================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Build Ground Truth:\n",
    "actual_courses_all = defaultdict(list)\n",
    "actual_courses_B = defaultdict(list)\n",
    "\n",
    "for uid, iid, true_r, est, _ in pred_user:\n",
    "    actual_courses_all[uid].append(iid)\n",
    "\n",
    "    if true_r >= 3.0:  # grade >= B\n",
    "        actual_courses_B[uid].append(iid)\n",
    "\n",
    "\n",
    "def precision_recall_at_k(top_n, actual_dict, K=5):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for uid, user_recs in top_n.items():\n",
    "        recommended_items = [iid for iid, _ in user_recs[:K]]\n",
    "        actual_items = actual_dict.get(uid, [])\n",
    "\n",
    "        if len(actual_items) == 0:\n",
    "            continue\n",
    "\n",
    "        true_positives = len(set(recommended_items) & set(actual_items))\n",
    "\n",
    "        precision = true_positives / K\n",
    "        recall = true_positives / len(actual_items)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    precision_avg = sum(precisions) / len(precisions)\n",
    "    recall_avg = sum(recalls) / len(recalls)\n",
    "    return precision_avg, recall_avg\n",
    "\n",
    "\n",
    "# --------- Calculate results for K = 5 and 10 -----------\n",
    "K_values = [5, 10]\n",
    "\n",
    "print(\"\\n====================== Precision & Recall ======================\")\n",
    "\n",
    "for K in K_values:\n",
    "    precision_all, recall_all = precision_recall_at_k(top_n_recommendations, actual_courses_all, K)\n",
    "    precision_B, recall_B = precision_recall_at_k(top_n_recommendations, actual_courses_B, K)\n",
    "\n",
    "    print(f\"\\n========== K = {K} ==========\")\n",
    "    print(\"-- Using ALL enrolled courses --\")\n",
    "    print(f\"Precision@{K}: {precision_all:.4f}\")\n",
    "    print(f\"Recall@{K}: {recall_all:.4f}\")\n",
    "\n",
    "    print(\"\\n-- Using ONLY courses with grade >= B --\")\n",
    "    print(f\"Precision@{K}: {precision_B:.4f}\")\n",
    "    print(f\"Recall@{K}: {recall_B:.4f}\")\n",
    "\n",
    "print(\"===================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kHpNvrN6-ESD",
    "outputId": "7fe009bb-28a2-412b-b218-dcd0d76034c6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 5.1 Visualization Function ===\n",
    "def visualize_topk_by_rank(top_n_recommendations, K=5, top_m=10):\n",
    "    \"\"\"\n",
    "    Visualizes the frequency of recommended courses by rank.\n",
    "    K: Number of recommendations per student.\n",
    "    top_m: Number of top courses to show in the chart.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for student_id, recs in top_n_recommendations.items():\n",
    "        for r, (course, score) in enumerate(recs[:K], start=1):\n",
    "            rows.append({\"rank\": r, \"course\": course})\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No recommendations to visualize.\")\n",
    "        return\n",
    "\n",
    "    df_viz = pd.DataFrame(rows)\n",
    "    rank_counters = {r: Counter(df_viz[df_viz[\"rank\"] == r][\"course\"]) for r in range(1, K+1)}\n",
    "\n",
    "    for r in range(1, K+1):\n",
    "        counter = rank_counters[r]\n",
    "        if not counter: continue\n",
    "\n",
    "        most_common = counter.most_common(top_m)\n",
    "        courses = [c for c, _ in most_common]\n",
    "        counts  = [cnt for _, cnt in most_common]\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.bar(courses, counts, color='skyblue')\n",
    "        plt.title(f\"Top {top_m} Courses @ Rank {r}\")\n",
    "        plt.xlabel(\"Course\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# === 5.2 Run Visualization ===\n",
    "print(\"--- Visualization of Recommendations ---\")\n",
    "visualize_topk_by_rank(top_n_recommendations, K=5, top_m=10)\n",
    "\n",
    "# === 5.3 Create Final DataFrame ===\n",
    "rows = []\n",
    "for student_id, recs in top_n_recommendations.items():\n",
    "    for rank, (course, predicted_grade) in enumerate(recs, start=1):\n",
    "        # Note: Data was filtered for INT in step 2, so this check is just a safeguard\n",
    "        if isinstance(course, str) and course.startswith(\"INT\"):\n",
    "            rows.append({\n",
    "                \"student_id\": student_id,\n",
    "                \"rank\": rank,\n",
    "                \"course\": course,\n",
    "                \"predicted_grade\": predicted_grade\n",
    "            })\n",
    "\n",
    "df_recommendations = pd.DataFrame(rows)\n",
    "\n",
    "print(\"\\n--- Final Recommendations Preview ---\")\n",
    "display(df_recommendations.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ-UK6fV9mgy"
   },
   "source": [
    "## 6.Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-yjtQ4yN9pLN",
    "outputId": "1c41c82d-a405-49cf-e86b-c019d4c37c62"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1. Define Mapping: Score -> Letter\n",
    "# ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Matrix ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°\n",
    "score_to_letter = {\n",
    "    0.0: 'F', 1.0: 'D', 1.5: 'D+', 2.0: 'C', 2.5: 'C+',\n",
    "    3.0: 'B', 3.5: 'B+', 4.0: 'A'\n",
    "}\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á list ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ (‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏£‡∏∞‡∏ö‡∏∏ Labels)\n",
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô map (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏°‡∏µ F)\n",
    "valid_scores = sorted(score_to_letter.keys())\n",
    "valid_labels = [score_to_letter[s] for s in valid_scores]\n",
    "\n",
    "# 2. Helper function: ‡∏´‡∏≤‡πÄ‡∏Å‡∏£‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "def get_nearest_grade_key(pred_score):\n",
    "    # ‡∏´‡∏≤ key (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô) ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "    return min(valid_scores, key=lambda x: abs(x - pred_score))\n",
    "\n",
    "# 3. Prepare Data\n",
    "y_true_letters = []\n",
    "y_pred_letters = []\n",
    "\n",
    "for pred in pred_user:\n",
    "    # 3.1 ‡πÅ‡∏õ‡∏•‡∏á Actual Grade (r_ui) ‡πÄ‡∏õ‡πá‡∏ô Letter\n",
    "    # ‡πÉ‡∏ä‡πâ get_nearest_grade_key ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤ r_ui ‡∏°‡∏µ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢\n",
    "    true_score_key = get_nearest_grade_key(pred.r_ui)\n",
    "    y_true_letters.append(score_to_letter[true_score_key])\n",
    "\n",
    "    # 3.2 ‡πÅ‡∏õ‡∏•‡∏á Predicted Grade (est) ‡πÄ‡∏õ‡πá‡∏ô Letter\n",
    "    pred_score_key = get_nearest_grade_key(pred.est)\n",
    "    y_pred_letters.append(score_to_letter[pred_score_key])\n",
    "\n",
    "# 4. Generate Confusion Matrix\n",
    "# ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà labels=valid_labels ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö (D -> A)\n",
    "cm = confusion_matrix(y_true_letters, y_pred_letters, labels=valid_labels)\n",
    "\n",
    "# 5. Plot Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=valid_labels,\n",
    "            yticklabels=valid_labels)\n",
    "\n",
    "plt.title('Confusion Matrix: Actual vs Predicted Grades')\n",
    "plt.xlabel('Predicted Grade')\n",
    "plt.ylabel('Actual Grade')\n",
    "plt.show()\n",
    "\n",
    "# 6. Classification Report\n",
    "print(\"\\n--- Detailed Classification Report ---\")\n",
    "print(classification_report(y_true_letters, y_pred_letters, target_names=valid_labels, zero_division=0,labels=valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NK-V5Q__-GT",
    "outputId": "25c9d23c-bb49-4a56-e9e8-5f9d47a080dd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_true_raw = [pred.r_ui for pred in pred_user]\n",
    "y_pred_raw = [pred.est for pred in pred_user]\n",
    "\n",
    "# 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì R2 Score\n",
    "r2 = r2_score(y_true_raw, y_pred_raw)\n",
    "\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "q4mlr9Nh6yIS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "258dac27-45dc-4ec5-ed98-83ef87113bda"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# data = Dataset.load_from_df(df_long_filtered[['student_id', 'course', 'grade']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    'k': [10, 20, 40],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson', 'msd', 'euclidean'],\n",
    "        'user_based': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SUEc5WMe9dpW",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cfc90504-b0f6-4295-f6d1-0f1eaba5518f"
   },
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö KNNBasic\n",
    "param_grid = {\n",
    "    'k': [20, 40, 60],\n",
    "    'min_k': [1, 5],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson'],\n",
    "        'user_based': [True, False]   # True=User‚ÄìUser, False=Item‚ÄìItem\n",
    "    }\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    KNNBasic,\n",
    "    param_grid,\n",
    "    measures=['rmse', 'mae'],\n",
    "    cv=5,\n",
    "    joblib_verbose=3\n",
    ")\n",
    "\n",
    "print(\"üöÄ Start GridSearchCV (KNN)...\")\n",
    "gs.fit(data)\n",
    "print(\"‚úÖ GridSearchCV Finished\")\n",
    "\n",
    "print(\"\\nüéØ Best RMSE:\", gs.best_score['rmse'])\n",
    "print(\"üèÜ Best parameters:\", gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "RmuzlbkxLDkh",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "664e427f-3e07-4088-9ffb-5a3e942a5ab5"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [110, 120, 130],\n",
    "    'n_epochs':  [80, 90, 100],\n",
    "    'reg_pu':    [0.04, 0.06, 0.08], # Regularization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö user latent factors\n",
    "    'reg_qi':    [0.04, 0.06, 0.08], # Regularization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö item latent factors\n",
    "    'min_k': [1, 5],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson', 'msd'],\n",
    "        'user_based': [True, False]   # True=User‚ÄìUser, False=Item‚ÄìItem\n",
    "    }\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    KNNBasic,\n",
    "    param_grid,\n",
    "    measures=['rmse', 'mae'],\n",
    "    cv=5,    # fold cross-validation\n",
    "    joblib_verbose=3\n",
    ")\n",
    "\n",
    "print(\"üöÄ Start GridSearchCV (KNN)...\")\n",
    "gs.fit(data)\n",
    "print(\"‚úÖ GridSearchCV Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "xwcukHpr_nTA",
    "outputId": "053e54ae-05c6-4510-ef33-3d4f5899fad9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Grid Search ‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "results_df = pd.DataFrame(gs.cv_results)\n",
    "\n",
    "# ‡πÅ‡∏ï‡∏Å params dict ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "params_df = results_df['params'].apply(pd.Series)\n",
    "\n",
    "# ‡∏£‡∏ß‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö metric ‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à\n",
    "df = pd.concat([\n",
    "    params_df,\n",
    "    results_df[['mean_test_rmse', 'mean_test_mae']]\n",
    "], axis=1)\n",
    "\n",
    "# ‡πÅ‡∏¢‡∏Å‡∏Ñ‡πà‡∏≤ name ‡πÅ‡∏•‡∏∞ user_based ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å sim_options\n",
    "df['sim_name'] = df['sim_options'].apply(lambda x: x['name'])\n",
    "df['user_based'] = df['sim_options'].apply(lambda x: x['user_based'])\n",
    "\n",
    "print(\"Best RMSE score:\", gs.best_score['rmse'])\n",
    "print(\"Best params for RMSE:\")\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "print(\"\\nBest MAE score:\", gs.best_score['mae'])\n",
    "print(\"Best params for MAE:\")\n",
    "print(gs.best_params['mae'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df,\n",
    "    x='k',\n",
    "    y='mean_test_rmse',\n",
    "    hue='sim_name',\n",
    "    marker='o',\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "plt.title('Effect of k on RMSE for KNN')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('RMSE (Lower is Better)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "_nR6u9TMXoVc",
    "outputId": "9f28d3ad-eb4b-4bf2-8deb-10046e54be54"
   },
   "outputs": [],
   "source": [
    "# 1. ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Grid Search ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏•‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü‡∏á‡πà‡∏≤‡∏¢\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Graph 1: Effect of Epochs (Learning Curve)\n",
    "# ‡∏î‡∏π‡∏ß‡πà‡∏≤ \"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\" ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠ Error ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\n",
    "# -------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# ‡πÅ‡∏Å‡∏ô X: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Epochs\n",
    "# ‡πÅ‡∏Å‡∏ô Y: ‡∏Ñ‡πà‡∏≤ Error (RMSE)\n",
    "# Hue (‡∏™‡∏µ‡πÄ‡∏™‡πâ‡∏ô): ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Factors (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•)\n",
    "sns.lineplot(data=results_df, x='param_n_epochs', y='mean_test_rmse',\n",
    "             hue='param_n_factors', marker='o', palette='viridis')\n",
    "\n",
    "plt.title('Effect of Epochs on RMSE (Learning Curve)')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('RMSE (Lower is Better)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "jSiYR5U9B8XT",
    "outputId": "6a34ecde-dcdd-4d47-8618-19a316f312a6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.plot(x='k', y='mean_test_rmse')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"K vs RMSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "O9HsYwXV_yW4",
    "outputId": "04b2cb19-448d-4e66-c1e7-832f4db2f611"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Graph 2: Heatmap (reg_pu vs reg_qi)\n",
    "# ‡∏î‡∏π‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà RMSE ‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏π‡πà‡∏Ç‡∏≠‡∏á regularization\n",
    "# -------------------------------------------------------\n",
    "pivot_table = results_df.pivot_table(\n",
    "    values='mean_test_rmse',\n",
    "    index='param_reg_pu',    # ‡πÅ‡∏Å‡∏ô‡∏ï‡∏±‡πâ‡∏á: reg_pu\n",
    "    columns='param_reg_qi'   # ‡πÅ‡∏Å‡∏ô‡∏ô‡∏≠‡∏ô: reg_qi\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    pivot_table,\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    cmap='Blues_r'  # ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏° = RMSE ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥ (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)\n",
    ")\n",
    "\n",
    "plt.title('RMSE Heatmap (KNN)')\n",
    "plt.xlabel('reg_qi (item regularization)')\n",
    "plt.ylabel('reg_pu (user regularization)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "vcX_S6ApwAsS",
    "outputId": "57e25769-776e-4a0e-c4ab-9d6cb6fbd418"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Graph: Heatmap (k vs similarity metric)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏• GridSearch ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ DataFrame\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "\n",
    "# NOTE:\n",
    "# param_sim_options ‡πÄ‡∏õ‡πá‡∏ô dict ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ï‡∏Å‡∏Ñ‡πà‡∏≤ metric ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô\n",
    "results_df['metric'] = results_df['param_sim_options'].apply(lambda x: x['name'])\n",
    "\n",
    "# ‡∏ó‡∏≥ pivot table\n",
    "pivot_table = results_df.pivot_table(\n",
    "    values='mean_test_rmse',\n",
    "    index='param_k',      # ‡πÅ‡∏Å‡∏ô‡∏ï‡∏±‡πâ‡∏á: k\n",
    "    columns='metric'      # ‡πÅ‡∏Å‡∏ô‡∏ô‡∏≠‡∏ô: similarity metric\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(\n",
    "    pivot_table,\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    cmap='Blues_r'   # ‡∏Ñ‡πà‡∏≤‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏°‡∏Å‡∏ß‡πà‡∏≤ = ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ (RMSE ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤)\n",
    ")\n",
    "\n",
    "plt.title('RMSE Heatmap (KNN) ‚Äî k vs Similarity Metric')\n",
    "plt.xlabel('Similarity Metric')\n",
    "plt.ylabel('k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "REcoAf7ewIZE",
    "outputId": "7a9c0d67-53bf-433c-ddbf-bb524683caaf"
   },
   "outputs": [],
   "source": [
    "pivot_table = results_df.pivot_table(\n",
    "    values='mean_test_rmse',\n",
    "    index='param_k',\n",
    "    columns='param_min_k'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.heatmap(\n",
    "    pivot_table,\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    cmap='Blues_r'\n",
    ")\n",
    "\n",
    "plt.title('RMSE Heatmap (KNN) ‚Äî k vs min_k')\n",
    "plt.xlabel('min_k')\n",
    "plt.ylabel('k')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "surprise-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
