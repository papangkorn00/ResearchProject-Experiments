{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acaeec08",
   "metadata": {},
   "source": [
    "## 1.Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c163a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from surprise import NMF\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define path\n",
    "data_path = '/home/sysadmin/ResearchProject-Experiments/datasets/student_grade.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753ed56",
   "metadata": {},
   "source": [
    "## 2.Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Error: The file '{data_path}' was not found.\")\n",
    "else:\n",
    "    print(\"File found. Loading data...\")\n",
    "\n",
    "    # === 2.1 Load Data ===\n",
    "    df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "    # === 2.2 Transform Data (Wide to Long) ===\n",
    "    id_vars = ['student_id']\n",
    "    df_long = pd.melt(df, id_vars=id_vars, var_name='course', value_name='grade')\n",
    "\n",
    "    # === 2.3 Clean Data ===\n",
    "    # Convert grade to numeric and remove invalid/empty grades\n",
    "    df_long['grade'] = pd.to_numeric(df_long['grade'], errors='coerce')\n",
    "    df_long_cleaned = df_long[(df_long['grade'] > 0.0) & (df_long['grade'].notna())].copy()\n",
    "\n",
    "    # === 2.4 Filter for 'INT' Courses Only ===\n",
    "    # This ensures the model only learns from INT courses\n",
    "    df_long_filtered = df_long_cleaned[df_long_cleaned['course'].astype(str).str.startswith('INT')].copy()\n",
    "\n",
    "    print(f\"--- Data Preparation Complete ---\")\n",
    "    print(f\"Total records after cleaning: {len(df_long_cleaned)}\")\n",
    "    print(f\"Filtered to INT courses only: {len(df_long_filtered)}\")\n",
    "    display(df_long_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809bf3f",
   "metadata": {},
   "source": [
    "## 3.Load Data and adjust rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rating scale (assuming grades are 1.0 to 4.0)\n",
    "reader = Reader(rating_scale=(1, 4))\n",
    "data = Dataset.load_from_df(df_long_filtered[['student_id', 'course', 'grade']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197204bb",
   "metadata": {},
   "source": [
    "## 4.Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1083e631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Start GridSearchCV (NMF)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=1)]: Done 127 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=1)]: Done 511 tasks      | elapsed:  6.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GridSearchCV Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  6.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [90, 110, 120, 130],\n",
    "    'n_epochs':  [70, 90, 110],\n",
    "    # 'n_factors': [50, 70, 90, 110],\n",
    "    # 'n_epochs': [80, 90, 100],\n",
    "    'reg_pu':    [0.04, 0.06, 0.08], # Regularization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö user latent factors\n",
    "    'reg_qi':    [0.04, 0.06, 0.08] # Regularization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö item latent factors\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    NMF,\n",
    "    param_grid,\n",
    "    measures=['rmse', 'mae'],\n",
    "    cv=5,    # fold cross-validation\n",
    "    joblib_verbose=3\n",
    ")\n",
    "\n",
    "print(\"üöÄ Start GridSearchCV (NMF)...\")\n",
    "gs.fit(data)\n",
    "print(\"‚úÖ GridSearchCV Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77cd7bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.5542039872177911\n",
      "Best params for RMSE:\n",
      "{'n_factors': 120, 'n_epochs': 110, 'reg_pu': 0.04, 'reg_qi': 0.04}\n",
      "\n",
      "Best MAE score: 0.43490108271126005\n",
      "Best params for MAE:\n",
      "{'n_factors': 110, 'n_epochs': 110, 'reg_pu': 0.04, 'reg_qi': 0.04}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE score:\", gs.best_score['rmse'])\n",
    "print(\"Best params for RMSE:\")\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "print(\"\\nBest MAE score:\", gs.best_score['mae'])\n",
    "print(\"Best params for MAE:\")\n",
    "print(gs.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e08da0",
   "metadata": {},
   "source": [
    "### RMSE DataFram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4353f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Grid Search ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏•‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü‡∏á‡πà‡∏≤‡∏¢\n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Graph 1: Effect of Epochs (Learning Curve)\n",
    "# ‡∏î‡∏π‡∏ß‡πà‡∏≤ \"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\" ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠ Error ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\n",
    "# -------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# ‡πÅ‡∏Å‡∏ô X: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Epochs\n",
    "# ‡πÅ‡∏Å‡∏ô Y: ‡∏Ñ‡πà‡∏≤ Error (RMSE)\n",
    "# Hue (‡∏™‡∏µ‡πÄ‡∏™‡πâ‡∏ô): ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Factors (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•)\n",
    "sns.lineplot(data=results_df, x='param_n_epochs', y='mean_test_rmse',\n",
    "             hue='param_n_factors', marker='o', palette='viridis')\n",
    "\n",
    "plt.title('Effect of Epochs on RMSE (Learning Curve)')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('RMSE (Lower is Better)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d42e9f",
   "metadata": {},
   "source": [
    "### RMSE Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ef594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Graph 2: Heatmap (reg_pu vs reg_qi)\n",
    "# ‡∏î‡∏π‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà RMSE ‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏π‡πà‡∏Ç‡∏≠‡∏á regularization\n",
    "# -------------------------------------------------------\n",
    "pivot_table = results_df.pivot_table(\n",
    "    values='mean_test_rmse',\n",
    "    index='param_reg_pu',    # ‡πÅ‡∏Å‡∏ô‡∏ï‡∏±‡πâ‡∏á: reg_pu\n",
    "    columns='param_reg_qi'   # ‡πÅ‡∏Å‡∏ô‡∏ô‡∏≠‡∏ô: reg_qi\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    pivot_table,\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    cmap='Blues_r'  # ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏° = RMSE ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥ (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)\n",
    ")\n",
    "\n",
    "plt.title('RMSE Heatmap (NMF): reg_pu vs reg_qi')\n",
    "plt.xlabel('reg_qi (item regularization)')\n",
    "plt.ylabel('reg_pu (user regularization)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
